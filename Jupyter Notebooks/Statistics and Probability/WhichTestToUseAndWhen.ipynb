{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing in Statistics and Data Science\n",
    "\n",
    "In statistics and data science, hypothesis testing is a fundamental process used to assess the validity of an assumption (hypothesis) based on sample data. The type of test you choose depends on factors like the type of data, sample size, number of groups, and the goal of the analysis (comparing means, proportions, variances, etc.). Here's an overview of when and how to use different tests for hypothesis testing:\n",
    "\n",
    "### 1. **Z-Test**\n",
    "- **Purpose**: Used to compare the sample mean to a known population mean when the population standard deviation is known, typically with large sample sizes (n ≥ 30).\n",
    "- **Types of Z-Tests**:\n",
    "  - **One-sample Z-test**: Comparing a single sample mean to a known population mean.\n",
    "  - **Two-sample Z-test**: Comparing the means of two independent samples when both population variances are known.\n",
    "  - **Proportion Z-test**: Comparing sample proportions to population proportions or comparing proportions between two samples.\n",
    "- **When to Use**:\n",
    "  - **One-sample Z-test**: When testing if a sample mean differs from a known population mean with known variance.\n",
    "  - **Two-sample Z-test**: Rarely used in practice due to unknown population variances.\n",
    "  - **Proportion Z-test**: When comparing proportions with large sample sizes.\n",
    "- **Assumptions**:\n",
    "  - The data follows a normal distribution or the sample size is large enough for the Central Limit Theorem to apply.\n",
    "  - Population variance (standard deviation) is known.\n",
    "  - Samples are independent.\n",
    "\n",
    "### 2. **T-Test**\n",
    "- **Purpose**: Used to compare means when the population standard deviation is unknown.\n",
    "- **Types of T-Tests**:\n",
    "  - **One-sample T-test**: Compare the sample mean to a known population mean.\n",
    "  - **Independent Two-sample T-test**:\n",
    "    - **Equal variances assumed (Student's T-test)**.\n",
    "    - **Unequal variances assumed (Welch's T-test)**.\n",
    "  - **Paired T-test**: Compare means from the same group at different times or under different conditions (dependent samples).\n",
    "- **When to Use**:\n",
    "  - **Any sample size**, especially when the sample size is small (n < 30).\n",
    "  - **Unknown population standard deviation**.\n",
    "  - Data is approximately normally distributed (robust to small deviations from normality).\n",
    "- **Assumptions**:\n",
    "  - For **Independent T-tests**:\n",
    "    - Samples are independent.\n",
    "    - Data in each group is normally distributed.\n",
    "    - Variances are equal (for Student's T-test) or unequal (for Welch's T-test).\n",
    "  - For **Paired T-test**:\n",
    "    - Differences between pairs are normally distributed.\n",
    "    - Pairs are matched or related.\n",
    "\n",
    "### 3. **Chi-Square Test**\n",
    "- **Purpose**: Used for categorical data to test relationships between variables or test the goodness-of-fit between observed and expected frequencies.\n",
    "- **Types of Chi-Square Tests**:\n",
    "  - **Chi-Square Goodness-of-Fit Test**: Compares observed frequencies with expected frequencies based on a theoretical distribution.\n",
    "  - **Chi-Square Test of Independence**: Tests if there is a relationship between two categorical variables (contingency tables).\n",
    "- **When to Use**:\n",
    "  - When both variables are categorical.\n",
    "  - Testing the independence between variables (e.g., gender and voting preference).\n",
    "  - Comparing observed vs. expected frequencies (e.g., testing a die for fairness).\n",
    "- **Assumptions**:\n",
    "  - Observations are independent.\n",
    "  - Expected frequency in each cell should be at least 5 (or no more than 20% of cells have expected frequencies less than 5, and all expected frequencies are at least 1).\n",
    "  - Data should be in the form of counts or frequencies.\n",
    "\n",
    "### 4. **F-Test**\n",
    "- **Purpose**: Used to compare variances between two populations or to assess if multiple groups have the same variance (important for ANOVA).\n",
    "- **When to Use**:\n",
    "  - When comparing the variances of two populations.\n",
    "  - As a preliminary test for ANOVA to check homogeneity of variance (though Levene's Test is more robust).\n",
    "- **Assumptions**:\n",
    "  - Data in each group is normally distributed.\n",
    "  - Samples are independent.\n",
    "- **Caveats**:\n",
    "  - Sensitive to departures from normality.\n",
    "  - Alternative tests like **Levene's Test** or **Bartlett's Test** can be used for testing equality of variances.\n",
    "\n",
    "### 5. **ANOVA (Analysis of Variance)**\n",
    "- **Purpose**: Used to compare the means of three or more groups.\n",
    "- **Types of ANOVA**:\n",
    "  - **One-way ANOVA**: Tests for differences in the means across three or more independent groups based on one factor.\n",
    "  - **Two-way ANOVA**: Tests for differences with two independent variables and can assess interaction effects.\n",
    "  - **Repeated Measures ANOVA**: Extension of the paired T-test for more than two time points or conditions.\n",
    "- **When to Use**:\n",
    "  - **One-way ANOVA**: Comparing means across multiple groups (e.g., test scores from different teaching methods).\n",
    "  - **Two-way ANOVA**: Analyzing the effect of two factors (e.g., teaching method and class size on test scores).\n",
    "- **Assumptions**:\n",
    "  - The residuals are normally distributed.\n",
    "  - Homogeneity of variances (homoscedasticity) across groups.\n",
    "  - Observations are independent.\n",
    "- **Post-Hoc Tests**:\n",
    "  - If ANOVA indicates significant differences, post-hoc tests (e.g., Tukey's HSD) are used to identify which groups differ.\n",
    "\n",
    "### 6. **Mann-Whitney U Test (Wilcoxon Rank-Sum Test)**\n",
    "- **Purpose**: A non-parametric test to compare two independent samples when the normality assumption is violated.\n",
    "- **When to Use**:\n",
    "  - Comparing distributions of two independent samples (alternative to independent T-test).\n",
    "  - Data is ordinal or continuous but not normally distributed.\n",
    "- **Assumptions**:\n",
    "  - Observations are independent.\n",
    "  - The distributions of the two groups have the same shape (for the test to compare medians).\n",
    "\n",
    "### 7. **Wilcoxon Signed-Rank Test**\n",
    "- **Purpose**: A non-parametric test used to compare two related samples when the normality assumption is violated.\n",
    "- **When to Use**:\n",
    "  - Comparing paired or matched samples (alternative to paired T-test).\n",
    "  - Data is ordinal or continuous but not normally distributed.\n",
    "- **Assumptions**:\n",
    "  - Differences between pairs are symmetrically distributed around the median.\n",
    "  - Observations are paired and come from the same population.\n",
    "\n",
    "### 8. **Kruskal-Wallis H Test**\n",
    "- **Purpose**: A non-parametric version of one-way ANOVA used to compare three or more independent groups when the normality assumption is violated.\n",
    "- **When to Use**:\n",
    "  - Comparing distributions across three or more groups (alternative to one-way ANOVA).\n",
    "  - Data is ordinal or continuous but not normally distributed.\n",
    "- **Assumptions**:\n",
    "  - Observations are independent.\n",
    "  - The distributions of the groups are similar in shape.\n",
    "\n",
    "### 9. **Correlation Tests**\n",
    "- **Pearson's Correlation Coefficient (r)**:\n",
    "  - **Purpose**: Measures the strength and direction of the linear relationship between two continuous variables.\n",
    "  - **When to Use**:\n",
    "    - Both variables are continuous and approximately normally distributed.\n",
    "    - The relationship is linear.\n",
    "  - **Assumptions**:\n",
    "    - Variables are normally distributed.\n",
    "    - Linear relationship exists.\n",
    "    - No significant outliers.\n",
    "- **Spearman's Rank Correlation Coefficient (ρ)**:\n",
    "  - **Purpose**: A non-parametric measure of rank correlation; assesses how well the relationship between two variables can be described by a monotonic function.\n",
    "  - **When to Use**:\n",
    "    - Data is ordinal, interval, or ratio but not normally distributed.\n",
    "    - Relationship is monotonic but not necessarily linear.\n",
    "  - **Assumptions**:\n",
    "    - Observations are independent.\n",
    "    - Variables are at least ordinal.\n",
    "\n",
    "### 10. **Fisher's Exact Test**\n",
    "- **Purpose**: Used to determine if there are nonrandom associations between two categorical variables in a 2x2 contingency table.\n",
    "- **When to Use**:\n",
    "  - When sample sizes are small and the Chi-Square Test assumptions are not met.\n",
    "  - In 2x2 tables regardless of sample size for exact results.\n",
    "- **Assumptions**:\n",
    "  - Data are counts or frequencies.\n",
    "  - Observations are independent.\n",
    "\n",
    "### 11. **McNemar's Test**\n",
    "- **Purpose**: Used on paired nominal data to determine whether the row and column marginal frequencies are equal.\n",
    "- **When to Use**:\n",
    "  - Testing for changes in responses using paired data (e.g., before and after treatment).\n",
    "- **Assumptions**:\n",
    "  - Data are paired and nominal.\n",
    "  - Observations are independent within pairs.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table of Test Selection\n",
    "\n",
    "| Test                         | Purpose                                         | Data Type           | Sample Size   | Key Assumptions                                         | Example Scenario                                          |\n",
    "|------------------------------|-------------------------------------------------|---------------------|---------------|---------------------------------------------------------|-----------------------------------------------------------|\n",
    "| **Z-Test**                   | Compare means or proportions (1 or 2 samples)   | Continuous          | Large (n ≥ 30) | Known population variance, normality                    | Compare average height of sample to population mean       |\n",
    "| **T-Test**                   | Compare means (1 or 2 samples)                  | Continuous          | Any size      | Unknown population variance, normality                  | Compare average scores of two teaching methods            |\n",
    "| **Chi-Square Test**          | Test association between categorical variables  | Categorical         | Any size      | Expected count ≥ 5 in cells (some exceptions apply)     | Test if gender is associated with political preference    |\n",
    "| **F-Test**                   | Compare variances                               | Continuous          | Any size      | Normality, independent samples                          | Test if two populations have the same variance in height  |\n",
    "| **ANOVA**                    | Compare means across 3+ groups                  | Continuous          | Any size      | Normality, equal variances, independence                | Test if 3 teaching methods have different average scores  |\n",
    "| **Mann-Whitney U Test**      | Compare distributions of 2 independent samples  | Ordinal/Continuous  | Any size      | Independent samples, similar shaped distributions       | Compare satisfaction scores between two stores            |\n",
    "| **Wilcoxon Signed-Rank Test**| Compare paired samples                          | Ordinal/Continuous  | Any size      | Differences are symmetrically distributed               | Compare blood pressure before and after treatment         |\n",
    "| **Kruskal-Wallis H Test**    | Compare distributions across 3+ groups          | Ordinal/Continuous  | Any size      | Independent samples, similar shaped distributions       | Test if 3 stores have different customer satisfaction     |\n",
    "| **Pearson's Correlation**    | Assess linear relationship between variables    | Continuous          | Any size      | Normality, linearity, no outliers                       | Correlation between height and weight                     |\n",
    "| **Spearman's Correlation**   | Assess monotonic relationship between variables | Ordinal/Continuous  | Any size      | Monotonic relationship                                  | Correlation between rank in class and stress levels       |\n",
    "| **Fisher's Exact Test**      | Test association in small samples (2x2 tables)  | Categorical         | Small         | Data are counts, independence                           | Test if a new drug affects recovery rates                 |\n",
    "| **McNemar's Test**           | Test changes in paired nominal data             | Categorical         | Any size      | Paired data, independence within pairs                  | Test if a training program changes pass/fail rates        |\n",
    "\n",
    "---\n",
    "\n",
    "### Guidelines for Choosing the Right Test\n",
    "\n",
    "1. **Type of Data**:\n",
    "   - **Continuous**: Z-test, T-test, ANOVA, Pearson's Correlation.\n",
    "   - **Categorical**: Chi-Square Test, Fisher's Exact Test, McNemar's Test.\n",
    "   - **Ordinal or Non-normal Continuous**: Non-parametric tests (Mann-Whitney U, Wilcoxon Signed-Rank, Kruskal-Wallis H, Spearman's Correlation).\n",
    "\n",
    "2. **Number of Groups or Variables**:\n",
    "   - **One group**: One-sample tests (Z-test, T-test).\n",
    "   - **Two groups**:\n",
    "     - **Independent samples**: Independent T-test, Mann-Whitney U Test, Chi-Square Test.\n",
    "     - **Paired samples**: Paired T-test, Wilcoxon Signed-Rank Test, McNemar's Test.\n",
    "   - **Three or more groups**: ANOVA, Kruskal-Wallis H Test.\n",
    "\n",
    "3. **Independent vs. Paired Samples**:\n",
    "   - **Independent samples**: Groups are unrelated (e.g., different people in each group).\n",
    "   - **Paired samples**: Measurements are related (e.g., same subjects before and after treatment).\n",
    "\n",
    "4. **Assumptions**:\n",
    "   - **Parametric Tests** (Z-test, T-test, ANOVA):\n",
    "     - Normality of data (or residuals).\n",
    "     - Homogeneity of variances (equal variances).\n",
    "     - Independence of observations.\n",
    "   - **Non-parametric Tests**:\n",
    "     - Fewer assumptions about the data distribution.\n",
    "     - Used when data does not meet parametric test assumptions.\n",
    "\n",
    "5. **Sample Size**:\n",
    "   - **Large samples**: Z-test, but T-tests are acceptable due to the Central Limit Theorem.\n",
    "   - **Small samples**: T-tests, non-parametric tests.\n",
    "\n",
    "6. **Variances**:\n",
    "   - **Equal variances**: Use standard T-tests and ANOVA.\n",
    "   - **Unequal variances**: Use Welch's T-test, consider non-parametric alternatives.\n",
    "\n",
    "7. **Testing Relationships**:\n",
    "   - **Correlation**:\n",
    "     - **Linear relationship**: Pearson's Correlation.\n",
    "     - **Monotonic relationship**: Spearman's Rank Correlation.\n",
    "   - **Association between categorical variables**: Chi-Square Test, Fisher's Exact Test.\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Considerations\n",
    "\n",
    "- **Normality Tests**:\n",
    "  - **Shapiro-Wilk Test**: Tests for normality in small samples.\n",
    "  - **Kolmogorov-Smirnov Test**: Tests for normality in larger samples.\n",
    "\n",
    "- **Homogeneity of Variance Tests**:\n",
    "  - **Levene's Test**: Tests equality of variances; robust to departures from normality.\n",
    "  - **Bartlett's Test**: Tests equality of variances; sensitive to departures from normality.\n",
    "\n",
    "- **Effect Size Measures**:\n",
    "  - Important to report along with p-values to indicate the magnitude of differences or relationships (e.g., Cohen's d, Eta-squared).\n",
    "\n",
    "- **Multiple Comparisons**:\n",
    "  - When performing multiple tests, consider adjusting p-values to control for Type I error (e.g., Bonferroni correction).\n",
    "\n",
    "- **Confidence Intervals**:\n",
    "  - Provide additional information about the precision of estimates and should be reported alongside test statistics.\n",
    "\n",
    "---\n",
    "\n",
    "Each statistical test has its own assumptions and conditions. Selecting the appropriate test depends heavily on your data structure, the specific hypotheses you're testing, and whether the assumptions of the test are met. Always explore your data thoroughly before choosing a test, and consider consulting a statistician if in doubt."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
